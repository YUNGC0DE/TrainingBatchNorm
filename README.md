# Training BatchNorm and only BatchNorm

Эта реализация статьи https://arxiv.org/pdf/2003.00152.pdf показывает возможность обучения CIFAR10 при помощи <br>
рандомно ициализированных весов и только при помощи них.

В оригинальной статье предложено сравнение точности полученной модели на различных архитектурах:
 <ul>
 <li>ResNet(N), где N принадлежит (14, 32, 56, 110, 218, 434, 866) </li>
 <li>ResNet14-W, где W принадлежит (1, 2, ,4 ,8, 16, 32)</li>
 <li>VGG</li>
 </ul>
 <br>
И при различных обучаемых параметрах:
<ul>
    <li>Обучение только BatchNorm </li>
    <li>Обучение всех параметров модели</li>
    <li>Обучение рандомно взятых параметров сверточных слоев (кол-во пропорционально BN параметрам)</li>
</ul>

В данной реализации рассмотрены только ResNet<32, 56, 110> для сравнения BN-only с пропорциональным колличестом<br>
рандомных параметров сети

Увеличение глубины способствует приросту качества из-за увелечения общего числа обучаемых параметров. <br><br>
<b>Сравнение качества ResNet с различной глубиной:<b><br>
![image](images/ResNet32/accuracy.png?raw=true")
<br>
<br>
Как можно заметить, обучение только BN даёт более хорошее качество по сравнению с рандомными параметрами сети (2 F.P.C)
